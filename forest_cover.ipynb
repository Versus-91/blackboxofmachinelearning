{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "data = pd.read_csv(\"./datasets/covtype.csv\")\n",
    "df_name=data.columns\n",
    "df_name\n",
    "X=data.loc[:,'Elevation':'Soil_Type40']\n",
    "Y=le.fit_transform(data['Cover_Type'])\n",
    "#Features to be removed before the model\n",
    "rem=['Hillshade_3pm','Soil_Type7','Soil_Type8','Soil_Type14','Soil_Type15',\n",
    "     'Soil_Type21','Soil_Type25','Soil_Type28','Soil_Type36','Soil_Type37']\n",
    "#Remove the unwanted features\n",
    "X.drop(rem, axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,Y,\n",
    "                                                   shuffle=True,\n",
    "                                                   test_size=0.25,\n",
    "                                                   random_state=42,)\n",
    "def find_best_k(X, y, max_k=20, cv=5):\n",
    "    \"\"\"\n",
    "    Find the best k value for KNN classifier using cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input features\n",
    "    - y: Target variable\n",
    "    - max_k: Maximum value of k to try (default: 20)\n",
    "    - cv: Number of folds for cross-validation (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "    - best_k: Best value of k\n",
    "    - best_accuracy: Cross-validation accuracy with the best k\n",
    "    - best_model: Best KNN model with the best k\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define a range of k values to try\n",
    "    k_values = list(range(1, max_k + 1))\n",
    "\n",
    "    # Dictionary to store mean cross-validation accuracies for each k\n",
    "    cv_scores = {}\n",
    "\n",
    "    # Perform cross-validation for each k\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=cv)\n",
    "        cv_scores[k] = np.mean(scores)\n",
    "\n",
    "    # Find the best k based on cross-validation scores\n",
    "    best_k = max(cv_scores, key=cv_scores.get)\n",
    "    best_accuracy = cv_scores[best_k]\n",
    "\n",
    "    # Train the best KNN model on the full training set\n",
    "    best_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    return best_k, best_accuracy, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score of Decision Tree is  0.9364212787343463 0.8952662102923742\n",
      "The test accuracy score of logistic regression is  0.717486041596387 0.4908429384284287\n",
      "The test accuracy score of Decision Tree is  0.9568408225647663 0.9293206264164974\n",
      "The test accuracy score of XGBoost is  0.8709011173607429 0.8548544114249294\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train,y_train)\n",
    "preds_dt = dt_model.predict(X_test)\n",
    "print(\"The test accuracy score of Decision Tree is \",\n",
    "      accuracy_score(y_test, preds_dt), f1_score(y_test, preds_dt, average='macro'))\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train,y_train)\n",
    "preds_lr = lr_model.predict(X_test)\n",
    "print(\"The test accuracy score of logistic regression is \",\n",
    "      accuracy_score(y_test, preds_lr), f1_score(y_test, preds_lr, average='macro'))\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train,y_train)\n",
    "preds_rf = rf_model.predict(X_test)\n",
    "print(\"The test accuracy score of Decision Tree is \",\n",
    "      accuracy_score(y_test, preds_rf), f1_score(y_test, preds_rf, average='macro'))\n",
    "\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=1)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "preds_xgb = xgb_model.predict(X_test)\n",
    "print(\"The test accuracy score of XGBoost is \",\n",
    "      accuracy_score(y_test, preds_xgb), f1_score(y_test, preds_xgb, average='macro'))\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train,y_train)\n",
    "preds_knn = knn_model.predict(X_test)\n",
    "print(\"The test accuracy score of knn is \",\n",
    "      accuracy_score(y_test, preds_knn), f1_score(y_test, preds_knn, average='macro'))\n",
    "\n",
    "# instantiating the object and fitting\n",
    "svm_model = SVC(kernel='rbf', random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# predicting the values\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# displaying the test accuracy\n",
    "print(\"The test accuracy score of SVM is \", accuracy_score(\n",
    "    y_test, y_pred_svm), f1_score(y_test, y_pred_svm, average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutation_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\versu\\Desktop\\research\\eai\\forest_cover.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/versu/Desktop/research/eai/forest_cover.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m perm_importance \u001b[39m=\u001b[39m permutation_importance(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/versu/Desktop/research/eai/forest_cover.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     svm_model, X_test, y_test, n_repeats\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/versu/Desktop/research/eai/forest_cover.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m knn_model_perm_importance \u001b[39m=\u001b[39m permutation_importance(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/versu/Desktop/research/eai/forest_cover.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     knn_model, X_test, y_test, n_repeats\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/versu/Desktop/research/eai/forest_cover.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Get feature importances\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'permutation_importance' is not defined"
     ]
    }
   ],
   "source": [
    "perm_importance = permutation_importance(\n",
    "    svm_model, X_test, y_test, n_repeats=50, random_state=42,n_jobs=-1)\n",
    "knn_model_perm_importance = permutation_importance(\n",
    "    knn_model, X_test, y_test, n_repeats=50, random_state=42,n_jobs=-1)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importances = rf_model.feature_importances_\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "svm_importances = perm_importance\n",
    "logireg_importances = np.abs(lr_model.coef_[0])\n",
    "\n",
    "# Create a DataFrame with feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RandomForest': rf_importances,\n",
    "    'DecissionTree': dt_model.feature_importances_,\n",
    "    'XGBoost': xgb_importances,\n",
    "    'Logistice Regression': logireg_importances,\n",
    "    'Support Vector Mcahine': svm_importances.importances_mean,\n",
    "    'K Nearest Neighbor': knn_model_perm_importance.importances_mean,\n",
    "})\n",
    "\n",
    "display(feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
