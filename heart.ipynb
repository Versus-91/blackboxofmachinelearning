{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8390243902439024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy score of Decision Tree is  0.8390243902439024 0.8387788660899407\n",
      "The test accuracy score of Random Forest is  0.9073170731707317 0.9072817729534147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       107\n",
      "           1       0.86      0.97      0.91        98\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "The test accuracy score of Gradient Boosting Classifier is  1.0 1.0\n",
      "The test accuracy score of SVM is  0.8341463414634146 0.8334766819571866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>logistice regression</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.058656</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.084504</td>\n",
       "      <td>-0.008943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.022753</td>\n",
       "      <td>0.665423</td>\n",
       "      <td>0.018049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>0.028066</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.258174</td>\n",
       "      <td>-0.006992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chol</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.221437</td>\n",
       "      <td>-0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fbs</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>restecg</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>0.258026</td>\n",
       "      <td>-0.010244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thalach</td>\n",
       "      <td>0.110539</td>\n",
       "      <td>0.017297</td>\n",
       "      <td>0.384973</td>\n",
       "      <td>-0.002439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>exang</td>\n",
       "      <td>0.082139</td>\n",
       "      <td>0.028399</td>\n",
       "      <td>0.420773</td>\n",
       "      <td>-0.006992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.684682</td>\n",
       "      <td>0.016098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ca</td>\n",
       "      <td>0.102079</td>\n",
       "      <td>0.064413</td>\n",
       "      <td>0.762777</td>\n",
       "      <td>0.021951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_0</td>\n",
       "      <td>0.119114</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.508593</td>\n",
       "      <td>0.004553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_1</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.033976</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.001626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_2</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.411610</td>\n",
       "      <td>0.009593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cp_3</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.304124</td>\n",
       "      <td>0.014146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thal_0</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.032188</td>\n",
       "      <td>0.108378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thal_1</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.125290</td>\n",
       "      <td>-0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thal_2</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>0.365715</td>\n",
       "      <td>0.297535</td>\n",
       "      <td>0.000163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thal_3</td>\n",
       "      <td>0.114924</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.342554</td>\n",
       "      <td>0.015122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_0</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.056704</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>-0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>slope_1</td>\n",
       "      <td>0.040153</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.266115</td>\n",
       "      <td>-0.000813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>slope_2</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.018458</td>\n",
       "      <td>0.224226</td>\n",
       "      <td>-0.010407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  RandomForest   XGBoost  logistice regression       svm\n",
       "0        age      0.058656  0.024118              0.084504 -0.008943\n",
       "1        sex      0.026170  0.022753              0.665423  0.018049\n",
       "2   trestbps      0.028066  0.016627              0.258174 -0.006992\n",
       "3       chol      0.038274  0.015957              0.221437 -0.002114\n",
       "4        fbs      0.003936  0.012483              0.016439  0.000976\n",
       "5    restecg      0.007087  0.008784              0.258026 -0.010244\n",
       "6    thalach      0.110539  0.017297              0.384973 -0.002439\n",
       "7      exang      0.082139  0.028399              0.420773 -0.006992\n",
       "8    oldpeak      0.100282  0.030500              0.684682  0.016098\n",
       "9         ca      0.102079  0.064413              0.762777  0.021951\n",
       "10      cp_0      0.119114  0.137118              0.508593  0.004553\n",
       "11      cp_1      0.003943  0.033976              0.019837 -0.001626\n",
       "12      cp_2      0.032096  0.016284              0.411610  0.009593\n",
       "13      cp_3      0.010054  0.006192              0.304124  0.014146\n",
       "14    thal_0      0.002558  0.032188              0.108378  0.000000\n",
       "15    thal_1      0.001755  0.018142              0.125290 -0.003089\n",
       "16    thal_2      0.080905  0.365715              0.297535  0.000163\n",
       "17    thal_3      0.114924  0.032663              0.342554  0.015122\n",
       "18   slope_0      0.002424  0.056704              0.081918 -0.001463\n",
       "19   slope_1      0.040153  0.041227              0.266115 -0.000813\n",
       "20   slope_2      0.034847  0.018458              0.224226 -0.010407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "df = pd.read_csv(\"./datasets/heart.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./datasets/heart.csv\")\n",
    "print(df.shape)\n",
    "# --- Creating Dummy Variables for cp, thal and slope ---\n",
    "cp = pd.get_dummies(df['cp'], prefix='cp')\n",
    "thal = pd.get_dummies(df['thal'], prefix='thal')\n",
    "slope = pd.get_dummies(df['slope'], prefix='slope')\n",
    "\n",
    "# --- Merge Dummy Variables to Main Data Frame ---\n",
    "frames = [df, cp, thal, slope]\n",
    "df = pd.concat(frames, axis = 1)\n",
    "\n",
    "df = df.drop(columns = ['cp', 'thal', 'slope'])\n",
    "# --- Seperating Dependent Features ---\n",
    "x = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "comulmn_names = x.columns\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "logre = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n",
    "logre.fit(x_train, y_train)\n",
    "y_pred = logre.predict(x_test)\n",
    "display(accuracy_score(y_test, y_pred))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, criterion='entropy', min_samples_split=5,\n",
    "                                       splitter='random', random_state=1)\n",
    "# fitting the model\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# calculating the predictions\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "# displaying the test accuracy\n",
    "print(\"The test accuracy score of Decision Tree is \",\n",
    "      accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# instantiating the object\n",
    "rf =  RandomForestClassifier(n_estimators=20, random_state=2,max_depth=5)\n",
    "\n",
    "# fitting the model\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "# Display test accuracy and F1 score\n",
    "print(\"The test accuracy score of Random Forest is \",\n",
    "        accuracy_score(y_test, y_pred_rf), f1_score(y_test, y_pred_rf, average='macro'))\n",
    "print(classification_report(y_test,y_pred_rf))\n",
    "# instantiate the classifier\n",
    "xgb_classifier = xgboost.XGBClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# fitting the model\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_classifier.predict(x_test)\n",
    "# Display test accuracy and F1 score\n",
    "print(\"The test accuracy score of Gradient Boosting Classifier is \",\n",
    "        accuracy_score(y_test, y_pred_xgb), f1_score(y_test, y_pred_xgb, average='macro'))\n",
    "# instantiating the object and fitting\n",
    "clf = SVC(kernel='linear', C=1, random_state=42).fit(x_train, y_train)\n",
    "\n",
    "# predicting the values\n",
    "y_pred_svm = clf.predict(x_test)\n",
    "\n",
    "# displaying the test accuracy\n",
    "print(\"The test accuracy score of SVM is \", accuracy_score(\n",
    "    y_test, y_pred_svm), f1_score(y_test, y_pred_svm, average='macro'))\n",
    "perm_importance = permutation_importance(\n",
    "    clf, x_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importances = rf.feature_importances_\n",
    "xgb_importances = xgb_classifier.feature_importances_\n",
    "svm_importances = perm_importance\n",
    "logireg_importances = abs(logre.coef_[0])\n",
    "\n",
    "# Create a DataFrame with feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': comulmn_names,\n",
    "    'RandomForest': rf_importances,\n",
    "    'XGBoost': xgb_importances,\n",
    "    'logistice regression': logireg_importances,\n",
    "    'svm': svm_importances.importances_mean,\n",
    "\n",
    "})\n",
    "\n",
    "display(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Melt the DataFrame for easy plotting\n",
    "melted = feature_importances.melt(id_vars='Feature', var_name='Model', value_name='Importance')\n",
    "\n",
    "# Create a grid plot using Seaborn\n",
    "grid_plot = sns.catplot(\n",
    "    data=melted, kind='bar',\n",
    "    x='Feature', y='Importance', hue='Model',\n",
    "    palette='viridis', alpha=0.8, height=6, aspect=2\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Feature Importances by Model')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "feature_names = [0, 1, 2, 3]\n",
    "\n",
    "# Decision Tree\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"XGBoost - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(dt, X_train, features=[\"thal\",\"age\"], ax=ax,categorical_features=[\"thal\"])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
