{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./datasets/heart.csv\")\n",
    "df1 = df.copy()  # Create a copy of the dataframe\n",
    "\n",
    "# Define the columns to be encoded and scaled\n",
    "cat_cols = ['sex', 'exng', 'caa', 'cp', 'fbs', 'restecg', 'slp', 'thall']\n",
    "con_cols = [\"age\", \"trtbps\", \"chol\", \"thalachh\", \"oldpeak\"]\n",
    "\n",
    "# Encoding the categorical columns\n",
    "df1 = pd.get_dummies(df1, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Define the features and target\n",
    "X = df1.drop(['output'], axis=1)\n",
    "y = df1['output']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = MinMaxScaler()\n",
    "# X_train_normalized = scaler.fit_transform(X_train)\n",
    "# X_test_normalized = scaler.transform(X_test)\n",
    "# X_train_normalized = pd.DataFrame(X_train_normalized, columns=X.columns)\n",
    "# X_test_normalized = pd.DataFrame(X_test_normalized, columns=X.columns)\n",
    "\n",
    "X_train_normalized = X_train\n",
    "X_test_normalized = X_test\n",
    "# Instantiate and fit the SVM model\n",
    "svm = SVC(kernel='linear', C=1, random_state=42,\n",
    "          probability=True).fit(X_train_normalized, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_svm = svm.predict(X_test_normalized)\n",
    "\n",
    "# Printing the test accuracy for SVM\n",
    "print(\"The test accuracy score of SVM is \", accuracy_score(\n",
    "    y_test, y_pred_svm), f1_score(y_test, y_pred_svm))\n",
    "\n",
    "# Instantiate and fit the Logistic Regression model\n",
    "logreg = LogisticRegression(penalty='none', max_iter=2000).fit(\n",
    "    X_train_normalized, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_logreg = logreg.predict(X_test_normalized)\n",
    "\n",
    "# Printing the test accuracy for Logistic Regression\n",
    "print(\"The test accuracy score of Logistic Regression is \", accuracy_score(\n",
    "    y_test, y_pred_logreg), f1_score(y_test, y_pred_logreg))\n",
    "\n",
    "# Instantiate and fit the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Printing the test accuracy for Decision Tree\n",
    "print(\"The test accuracy score of Decision Tree is \", accuracy_score(\n",
    "    y_test, y_pred_dt), \"f1 :\",  f1_score(y_test, y_pred_dt))\n",
    "\n",
    "# Instantiate and fit the Random Forest model\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Printing the test accuracy for Random Forest\n",
    "print(\"The test accuracy score of Random Forest is \", accuracy_score(\n",
    "    y_test, y_pred_rf), \"f1 :\",  f1_score(y_test, y_pred_rf))\n",
    "\n",
    "# Instantiate the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Printing the test accuracy for Gradient Boosting Classifier\n",
    "print(\"The test accuracy score of Gradient Boosting Classifier is \",\n",
    "      accuracy_score(y_test, y_pred_xgb), \"f1 :\",  f1_score(y_test, y_pred_xgb))\n",
    "\n",
    "# Instantiate the mlp\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 64),\n",
    "                    max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the mlp model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "# Printing the test accuracy for mlp Classifier\n",
    "print(\"The test accuracy score of MLP Classifier is \", accuracy_score(\n",
    "    y_test, y_pred_mlp), \"f1 :\",  f1_score(y_test, y_pred_mlp))\n",
    "\n",
    "# Instantiate the KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the mlp model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Printing the test accuracy for mlp Classifier\n",
    "print(\"The test accuracy score of knn Classifier is \", accuracy_score(\n",
    "    y_test, y_pred_mlp), \"f1 :\",  f1_score(y_test, y_pred_knn))\n",
    "# Calculate permutation importance for SVM\n",
    "perm_importance_svm = permutation_importance(\n",
    "    svm, X_test_normalized, y_test, n_repeats=30, random_state=42, n_jobs=50)\n",
    "\n",
    "# Get feature importances\n",
    "rf_importances = rf.feature_importances_\n",
    "xgb_importances = xgb_classifier.feature_importances_\n",
    "logreg_importances = abs(logreg.coef_[0])\n",
    "current_importance_type = xgb_classifier.get_booster().get_score()\n",
    "print(current_importance_type)\n",
    "# Create a DataFrame with feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RandomForest': rf_importances,\n",
    "    'DecissionTree': dt.feature_importances_,\n",
    "    'XGBoost': xgb_importances,\n",
    "    'LogisticRegression': logreg_importances,\n",
    "    'SVM': perm_importance_svm.importances_mean,\n",
    "})\n",
    "\n",
    "# Display feature importances\n",
    "display(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "feature_names = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "# Decision Tree\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Decision Tree - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(dt, X, features=feature_names, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Logistic Regression\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Logistic Regression - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    logreg, X_train, features=feature_names, categorical_features=[\"sex_1\"], ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# SVM - Partial Dependence doesn't directly apply to SVM; consider other visualization methods\n",
    "# SVM doesn't inherently support partial dependence plots as decision tree-based models do.\n",
    "\n",
    "# XGBoost\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"XGBoost - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    xgb_classifier, X_train, features=feature_names, ax=ax, categorical_features=[\"sex_1\"])\n",
    "plt.show()\n",
    "\n",
    "# Random Forest\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Random Forest - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf, X_train, features=feature_names, ax=ax, categorical_features=[\"sex_1\"])\n",
    "plt.show()\n",
    "# MULTI LAYER PERCEPTRON\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"MLP - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    mlp, X_train, features=feature_names, ax=ax, categorical_features=[\"sex_1\"])\n",
    "plt.show()\n",
    "# KNN\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"KNN - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    knn, X_train, features=feature_names, ax=ax, categorical_features=[\"sex_1\"])\n",
    "plt.show()\n",
    "# SVM\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"SUPPORT VECTOR MACHINE - Partial Dependence\")\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    svm, X_train, features=feature_names, ax=ax, categorical_features=[\"sex_1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1) && (HRSWK>0)). The prediction task is to determine whether a person makes over $50K a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import lime\n",
    "import pdpbox\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"./datasets/adult.csv\")\n",
    "# Definition of the columns that will be features (note that the column 'clientid' is not present)\n",
    "features = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
    "    'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital.gain', 'capital.loss', 'hours.per.week', 'native.country'\n",
    "]\n",
    "\n",
    "# Preparation of arguments for ``scikit-learn`` library methods\n",
    "X = df[features].values\n",
    "# Part of transforming categorical to integer\n",
    "lbp = LabelEncoder()\n",
    "X[:, 1] = lbp.fit_transform(X[:, 1])\n",
    "\n",
    "X[:, 3] = lbp.fit_transform(X[:, 3])\n",
    "\n",
    "X[:, 5] = lbp.fit_transform(X[:, 5])\n",
    "\n",
    "X[:, 6] = lbp.fit_transform(X[:, 6])\n",
    "\n",
    "X[:, 7] = lbp.fit_transform(X[:, 7])\n",
    "X\n",
    "X[:, 8] = lbp.fit_transform(X[:, 8])\n",
    "\n",
    "X[:, 9] = lbp.fit_transform(X[:, 9])\n",
    "\n",
    "X[:, 13] = lbp.fit_transform(X[:, 13])\n",
    "\n",
    "LE = LabelEncoder()\n",
    "\n",
    "y = LE.fit_transform(df[\"income\"])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "# Instantiate and fit the SVM model\n",
    "svm = SVC(random_state=42, probability=True).fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "roc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "# Printing the test accuracy for SVM\n",
    "print(\"The test accuracy score of SVM is \", accuracy_score(\n",
    "    y_test, y_pred_svm), \"f1 :\",  f1_score(y_test, y_pred_svm))\n",
    "\n",
    "# Instantiate and fit the Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_logreg)\n",
    "f1_lr = f1_score(y_test, y_pred_logreg)\n",
    "precision_lr = precision_score(y_test, y_pred_logreg)\n",
    "recall_lr = recall_score(y_test, y_pred_logreg)\n",
    "roc_lr = roc_auc_score(y_test, y_pred_logreg)\n",
    "\n",
    "# Printing the test accuracy for Logistic Regression\n",
    "print(\"The test accuracy score of Logistic Regression is \", accuracy_score(\n",
    "    y_test, y_pred_logreg), \"f1 :\", f1_score(y_test, y_pred_logreg))\n",
    "\n",
    "# Instantiate and fit the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "roc_dt = roc_auc_score(y_test, y_pred_dt)\n",
    "\n",
    "# Printing the test accuracy for Decision Tree\n",
    "print(\"The test accuracy score of Decision Tree is \", accuracy_dt, \"f1 :\", f1_dt)\n",
    "\n",
    "# Instantiate and fit the Random Forest model\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Predicting values\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "# Printing the test accuracy for Random Forest\n",
    "print(\"The test accuracy score of Random Forest is \", accuracy_score(\n",
    "    y_test, y_pred_rf), \"f1 :\",  f1_score(y_test, y_pred_rf))\n",
    "\n",
    "# Instantiate the XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_xgb = xgb_classifier.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "roc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Printing the test accuracy for Gradient Boosting Classifier\n",
    "print(\"The test accuracy score of Gradient Boosting Classifier is \",\n",
    "      accuracy_score(y_test, y_pred_xgb), \"f1 :\",  f1_score(y_test, y_pred_xgb))\n",
    "\n",
    "# Instantiate the mlp\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 64),\n",
    "                    max_iter=2000, random_state=42)\n",
    "\n",
    "# Fit the mlp model\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict values\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "accuracy_rn = accuracy_score(y_test, y_pred_mlp)\n",
    "recall_rn = recall_score(y_test, y_pred_mlp)\n",
    "precision_rn = precision_score(y_test, y_pred_mlp)\n",
    "f1_rn = f1_score(y_test, y_pred_mlp)\n",
    "roc_rn = roc_auc_score(y_test, y_pred_mlp)\n",
    "# Printing the test accuracy for mlp Classifier\n",
    "print(\"The test accuracy score of MLP Classifier is \", accuracy_score(\n",
    "    y_test, y_pred_mlp), \"f1 :\",  f1_score(y_test, y_pred_mlp))\n",
    "\n",
    "# Instantiate the KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "roc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "# Printing the test accuracy for mlp Classifier\n",
    "print(\"The test accuracy score of knn Classifier is \", accuracy_score(\n",
    "    y_test, y_pred_knn), \"f1 :\", f1_score(y_test, y_pred_knn))\n",
    "# Calculate permutation importance for SVM\n",
    "models = [\n",
    "    ('Decision Tree', accuracy_dt, recall_dt, precision_dt, f1_dt, roc_dt),\n",
    "    ('Random Forest', accuracy_rf, recall_rf, precision_rf, f1_rf, roc_rf),\n",
    "    ('XGBoost', accuracy_xgb, recall_xgb, precision_xgb, f1_xgb, roc_xgb),\n",
    "    ('kNN', accuracy_knn, recall_knn, precision_knn, f1_knn, roc_knn),\n",
    "    ('Logistic Regression', accuracy_lr, recall_lr, precision_lr, f1_lr, roc_lr),\n",
    "    ('SVM', accuracy_svm, recall_svm, precision_svm, f1_svm, roc_svm),\n",
    "    ('Neural Networks', accuracy_rn, recall_rn, precision_rn, f1_rn, roc_rn)]\n",
    "\n",
    "df_all_models = pd.DataFrame(models, columns=[\n",
    "                             'Model', 'Accuracy (%)', 'Recall (%)', 'Precision (%)', 'F1 (%)', 'AUC'])\n",
    "display(df_all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass    fnlwgt     education  education-num  \\\n",
       "0       25       Private  226802.0          11th              7   \n",
       "1       38       Private   89814.0       HS-grad              9   \n",
       "2       28     Local-gov  336951.0    Assoc-acdm             12   \n",
       "3       44       Private  160323.0  Some-college             10   \n",
       "4       18           NaN  103497.0  Some-college             10   \n",
       "...    ...           ...       ...           ...            ...   \n",
       "48837   27       Private  257302.0    Assoc-acdm             12   \n",
       "48838   40       Private  154374.0       HS-grad              9   \n",
       "48839   58       Private  151910.0       HS-grad              9   \n",
       "48840   22       Private  201490.0       HS-grad              9   \n",
       "48841   52  Self-emp-inc  287927.0       HS-grad              9   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0               0.0           0.0              40  United-States  <=50K  \n",
       "1               0.0           0.0              50  United-States  <=50K  \n",
       "2               0.0           0.0              40  United-States   >50K  \n",
       "3            7688.0           0.0              40  United-States   >50K  \n",
       "4               0.0           0.0              30  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "48837           0.0           0.0              38  United-States  <=50K  \n",
       "48838           0.0           0.0              40  United-States   >50K  \n",
       "48839           0.0           0.0              40  United-States  <=50K  \n",
       "48840           0.0           0.0              20  United-States  <=50K  \n",
       "48841       15024.0           0.0              40  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openml\n",
    "dataset = openml.datasets.get_dataset(1590)\n",
    "X, y, _, _ = dataset.get_data(dataset_format=\"dataframe\")\n",
    "display(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
